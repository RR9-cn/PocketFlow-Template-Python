"""
Gemini API è°ƒç”¨å·¥å…·
ä½¿ç”¨å®˜æ–¹ Google Generative AI SDK
"""
import os
from google import genai

# åœ¨åˆå§‹åŒ–ä¹‹å‰è®¾ç½®ä»£ç†
# å¦‚æœéœ€è¦ä½¿ç”¨ä»£ç†ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šå¹¶ä¿®æ”¹ç«¯å£
# os.environ['http_proxy'] = 'http://127.0.0.1:15236'
# os.environ['https_proxy'] = 'http://127.0.0.1:15236'

def call_gemini(prompt: str, temperature: float = 1.0, model: str = "gemini-2.5-pro", stream: bool = True) -> str:
    """
    è°ƒç”¨ Google Gemini API ç”Ÿæˆå†…å®¹ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰

    Args:
        prompt: æç¤ºè¯
        temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶åˆ›é€ æ€§ (0.0-2.0)
        model: æ¨¡å‹åç§°
        stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º

    Returns:
        ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
    """
    # æ£€æµ‹ä»£ç†è®¾ç½®
    proxy = os.getenv("HTTP_PROXY") or os.getenv("http_proxy")
    print(f"ğŸŒ å½“å‰ä»£ç†: {proxy if proxy else 'æœªè®¾ç½®'}")

    if not proxy:
        # é»˜è®¤ä»£ç† - è¯·æ ¹æ®ä½ çš„å®é™…ä»£ç†ç«¯å£ä¿®æ”¹
        default_proxy = 'http://127.0.0.1:15236'  # å¸¸è§çš„ä»£ç†ç«¯å£
        print(f"âš ï¸  å°è¯•ä½¿ç”¨é»˜è®¤ä»£ç†: {default_proxy}")
        print(f"   å¦‚æœå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç†è½¯ä»¶æ˜¯å¦è¿è¡Œï¼Œæˆ–ä¿®æ”¹æ­¤ç«¯å£")
        os.environ['http_proxy'] = default_proxy
        os.environ['https_proxy'] = default_proxy

    # è·å– API Key
    api_key = os.getenv("GEMINI_API_KEY", "")
    if not api_key:
        raise ValueError("GEMINI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")

    print(f"âœ“ API Key: {api_key[:10]}...{api_key[-4:]}")

    try:
        client = genai.Client(api_key=api_key)

        if stream:
            # æµå¼è¾“å‡º
            print("ğŸ“¡ å¼€å§‹æµå¼ç”Ÿæˆ...")
            full_text = ""
            for chunk in client.models.generate_content_stream(
                model=model,
                contents=prompt,
                config={"temperature": temperature}
            ):
                text = chunk.text
                print(text, end='', flush=True)
                full_text += text
            print("\nâœ“ ç”Ÿæˆå®Œæˆ")
            return full_text
        else:
            # æ™®é€šè¾“å‡º
            print("ğŸ“¡ å¼€å§‹ç”Ÿæˆ...")
            response = client.models.generate_content(
                model=model,
                contents=prompt,
                config={"temperature": temperature}
            )
            print("âœ“ ç”Ÿæˆå®Œæˆ")
            return response.text

    except Exception as e:
        print(f"\nâœ— Gemini API è°ƒç”¨å¤±è´¥")
        print(f"   é”™è¯¯: {e}")
        print(f"   ç±»å‹: {type(e).__name__}")
        print("\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("   1. æ£€æŸ¥ä»£ç†è½¯ä»¶æ˜¯å¦è¿è¡Œï¼ˆå¦‚ Clashã€V2Rayï¼‰")
        print("   2. ç¡®è®¤ä»£ç†ç«¯å£æ˜¯å¦æ­£ç¡®ï¼ˆå¸¸è§: 7890, 7891, 1080, 15236ï¼‰")
        print("   3. å°è¯•ç›´æ¥è®¿é—® https://generativelanguage.googleapis.com")
        raise


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    test_prompt = "å†™ä¸€ä¸ª 100 å­—çš„ç§‘å¹»å°è¯´å¼€å¤´"

    print("è°ƒç”¨ Gemini API...:")
    response = call_gemini(test_prompt, temperature=1.2)
    print(f"å“åº”: {response}")
